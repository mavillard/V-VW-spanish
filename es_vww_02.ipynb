{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/out/stories.pickle', 'rb') as f:\n",
    "    stories = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/aux/es_lexicon.csv') as f:\n",
    "    reader = csv.reader(\n",
    "        f,\n",
    "        delimiter=' ',\n",
    "    )\n",
    "    lexicon = []\n",
    "    for row in reader:\n",
    "        for i in range(1, len(row[1:]), 2):\n",
    "            entry = {}\n",
    "            entry['flexion'] = row[0].lower()\n",
    "            entry['lemma'] = row[i].lower()\n",
    "            entry['eagle'] = row[i+1].lower()\n",
    "            lexicon.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = set(entry['flexion'] for entry in lexicon)\n",
    "nouns = set(entry['flexion'] for entry in lexicon if entry['eagle'].startswith('n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/aux/stopwords-es.txt') as f:\n",
    "    stop = [w.strip() for w in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuation = list(string.punctuation)\n",
    "weird = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '¡', '¢', '£', '¤', '¥', '¨', '©', '¬', '\\xad',\n",
    "    '°', '±', '³', '´', '·', '¾', '¿', '×', '́', '̃', '͜', '͡', '๏', '\\u200b', '‒', '–', '—', '―', '•',\n",
    "    '…', '\\u202a', '※', '€', '™', '↑', '→', '↓', '↘', '↙', '∆', '√', '∞', '∴', '∵', '⊙', '╥', '▁',\n",
    "    '▂', '▪', '▬', '▶', '◀', '◆', '◇', '○', '●', '◔', '◡', '☀', '★', '☆', '☺', '☻', '♠', '♡', '♢',\n",
    "    '♣', '♤', '♥', '♦', '♧', '⚜', '⚫', '✅', '✋', '✌', '✎', '✔', '✰', '✿', '❎', '❓', '❝', '❞', '❤',\n",
    "    '❥', '⬆', '⬇', '⭕', '《', '》', '️', '︿', '﹏', '\\ufeff', '｡', '�', '🌈', '🌊', '🌚', '🌟', '🌷',\n",
    "    '🌸', '🌹', '🌼', '🎁', '🎄', '🎉', '🎊', '🎶', '🏄', '🏻', '🏼', '🏽', '🐺', '🐻', '👀', '👉', '👊',\n",
    "    '👋', '👌', '👍', '👏', '👑', '👻', '💁', '💋', '💕', '💖', '💘', '💙', '💚', '💛', '💜', '💞', '💠',\n",
    "    '💩', '📖', '📚', '🔥', '🔫', '🖊', '🖐', '🖕', '😀', '😁', '😂', '😃', '😄', '😅', '😆', '😇', '😈',\n",
    "    '😉', '😊', '😋', '😌', '😍', '😎', '😏', '😐', '😓', '😔', '😕', '😖', '😘', '😙', '😚', '😜', '😝',\n",
    "    '😟', '😢', '😣', '😥', '😨', '😫', '😬', '😭', '😰', '😱', '😳', '😵', '😷', '😼', '🙂', '🙄', '🙇',\n",
    "    '🙈', '🙊', '🙏', '🤓', '🤗'\n",
    "]\n",
    "others = punctuation + weird\n",
    "# adverbs = [\n",
    "#     'ahora', 'antes', 'después', 'tarde', 'luego', 'ayer', 'temprano', 'ya', 'todavía', 'anteayer', 'aún',\n",
    "#     'pronto', 'hoy', 'aquí', 'ahí', 'allí', 'cerca', 'lejos', 'fuera', 'dentro', 'alrededor', 'aparte',\n",
    "#     'encima', 'debajo', 'delante', 'detrás', 'así', 'bien', 'mal', 'despacio', 'deprisa', 'como', 'mucho',\n",
    "#     'poco', 'muy', 'casi', 'todo', 'nada', 'algo', 'medio', 'demasiado', 'bastante', 'más', 'menos', 'además',\n",
    "#     'incluso', 'también', 'sí', 'también', 'asimismo', 'no', 'tampoco', 'jamás', 'nunca', 'acaso', 'quizá',\n",
    "#     'quizás', 'tal', 'vez', 'tan'\n",
    "# ]\n",
    "# prepositions = [\n",
    "#     'a', 'ante', 'bajo', 'cabe', 'con', 'contra', 'de', 'desde', 'en', 'entre', 'hacia', 'hasta', 'para',\n",
    "#     'por', 'según', 'sin', 'so', 'sobre', 'tras', 'durante', 'mediante', 'excepto', 'salvo', 'incluso',\n",
    "#     'más', 'menos',\n",
    "# ]\n",
    "stop += stopwords.words('english') + stopwords.words('spanish') + others # adverbs + prepositions\n",
    "\n",
    "my_own_stop_words = ['dije']\n",
    "stop += my_own_stop_words\n",
    "\n",
    "def remove_accent_marks(s):\n",
    "    return s.replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u')\n",
    "\n",
    "stop += [remove_accent_marks(w) for w in stop]\n",
    "\n",
    "def clean(s, only_nouns=True, no_accent_marks=True):\n",
    "    r = s.lower()\n",
    "    for p in others:\n",
    "        r = r.replace(p, '')\n",
    "    words = [w for w in nltk.word_tokenize(r) if w not in stop and not w.isnumeric() and len(w) > 1]\n",
    "    if only_nouns:\n",
    "        words = [w for w in words if w in nouns or w not in all_words]\n",
    "    r = ' '.join(words)\n",
    "    if no_accent_marks:\n",
    "        r = remove_accent_marks(r)\n",
    "    return r\n",
    "\n",
    "def join_texts(d):\n",
    "    return ' '.join(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 40 ms, total: 2min 29s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for story in stories:\n",
    "    story['texts'] = dict((k, clean(v)) for k, v in story['texts'].items())\n",
    "    story['text'] = join_texts(story['texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/out/clean_stories.pickle', 'wb') as f:\n",
    "    pickle.dump(stories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
